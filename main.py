import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from imblearn.over_sampling import RandomOverSampler
from sklearn.metrics.pairwise import cosine_similarity
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rc('font', family='Malgun Gothic')
plt.rc('axes', unicode_minus=False)

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
combined_data = pd.read_excel('combined_data.xlsx', sheet_name='Sheet1')
symptom_data = pd.read_excel('symptom_data.xlsx', sheet_name='Sheet1')

# 2. ë°ì´í„° ì „ì²˜ë¦¬
texts = symptom_data['text']
labels = symptom_data['ê±´ê°• ì¹´í…Œê³ ë¦¬']

# TF-IDF ë²¡í„°í™” (n-gram (1, 2) ì„¤ì • ë° max_features 1000ìœ¼ë¡œ ì¦ê°€)
tfidf_vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))
text_vectors = tfidf_vectorizer.fit_transform(texts)

# ë¼ë²¨ ì¸ì½”ë”©
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)

# í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)
X_train, X_test, y_train, y_test = train_test_split(
    text_vectors, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels
)

# 3. í•™ìŠµ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™” (ì˜¤ë²„ìƒ˜í”Œë§ ì „)
label_counts = Counter(y_train)
plt.bar(label_counts.keys(), label_counts.values())
plt.xticks(ticks=range(len(label_encoder.classes_)), labels=label_encoder.classes_, rotation=45)
plt.xlabel('ê±´ê°• ì¹´í…Œê³ ë¦¬')
plt.ylabel('ìƒ˜í”Œ ìˆ˜')
plt.title('í›ˆë ¨ ë°ì´í„°ì˜ ê±´ê°• ì¹´í…Œê³ ë¦¬ ë¶„í¬ (ì˜¤ë²„ìƒ˜í”Œë§ ì „)')
plt.savefig('train_data_distribution_before_oversampling.png')  # ì´ë¯¸ì§€ ì €ì¥
plt.close()

# 4. RandomOverSamplerë¥¼ ì´ìš©í•œ ë°ì´í„° ì¦ê°• (ë°ì´í„° ë¶ˆê· í˜• í•´ê²°)
ros = RandomOverSampler(random_state=42)
X_train, y_train = ros.fit_resample(X_train, y_train)

# ë°ì´í„° ì¦ê°• í›„ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
print("RandomOverSampler í›„ í›ˆë ¨ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶„í¬:")
print(Counter(y_train))

# 5. í•™ìŠµ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™” (ì˜¤ë²„ìƒ˜í”Œë§ í›„)
label_counts = Counter(y_train)
plt.bar(label_counts.keys(), label_counts.values())
plt.xticks(ticks=range(len(label_encoder.classes_)), labels=label_encoder.classes_, rotation=45)
plt.xlabel('ê±´ê°• ì¹´í…Œê³ ë¦¬')
plt.ylabel('ìƒ˜í”Œ ìˆ˜')
plt.title('í›ˆë ¨ ë°ì´í„°ì˜ ê±´ê°• ì¹´í…Œê³ ë¦¬ ë¶„í¬ (ì˜¤ë²„ìƒ˜í”Œë§ í›„)')
plt.savefig('train_data_distribution_after_oversampling.png')  # ì´ë¯¸ì§€ ì €ì¥
plt.close()

# 6. ëª¨ë¸ í•™ìŠµ
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
y_pred = model.predict(X_test)

# 7. ëª¨ë¸ í‰ê°€
print('ğŸ“ˆ Accuracy:', accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# 8. í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, cmap='Blues', 
            xticklabels=label_encoder.classes_, 
            yticklabels=label_encoder.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')
plt.savefig('confusion_matrix.png')  # ì´ë¯¸ì§€ ì €ì¥
plt.close()

# 9. ëª¨ë¸ ì €ì¥
joblib.dump(model, 'health_recommendation_model.pkl')
joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')
joblib.dump(label_encoder, 'label_encoder.pkl')

# 10. ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì¶”ì²œ ê¸°ëŠ¥ êµ¬í˜„ (ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ)
def recommend_health_products(user_input, top_n=5):
    # ì‚¬ìš©ì ì…ë ¥ ë²¡í„°í™”
    input_vector = tfidf_vectorizer.transform([user_input])
    
    # ê±´ê°• ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡
    predicted_category = model.predict(input_vector)
    category_name = label_encoder.inverse_transform(predicted_category)[0]
    
    # ì˜ˆì¸¡ëœ ê±´ê°• ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ í•„í„°ë§
    recommended_products = combined_data[combined_data['ê±´ê°• ì¹´í…Œê³ ë¦¬'] == category_name]
    
    # ì£¼ìš” ê¸°ëŠ¥ í…ìŠ¤íŠ¸ ë²¡í„°í™” (ì¶”ì²œ ì œí’ˆì˜ 'ì£¼ìš” ê¸°ëŠ¥' ì—´ ì‚¬ìš©)
    product_descriptions = recommended_products['ì£¼ìš” ê¸°ëŠ¥'].fillna('')
    product_vectors = tfidf_vectorizer.transform(product_descriptions)
    
    # ì‚¬ìš©ì ì…ë ¥ê³¼ ì œí’ˆ ì£¼ìš” ê¸°ëŠ¥ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(input_vector, product_vectors).flatten()
    
    # ìœ ì‚¬ë„ì— ë”°ë¼ ì œí’ˆì„ ì •ë ¬í•˜ê³  ìƒìœ„ Nê°œ ì„ íƒ
    top_indices = similarities.argsort()[::-1][:top_n]
    top_products = recommended_products.iloc[top_indices]
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ§  ì˜ˆì¸¡ëœ ê±´ê°• ì¹´í…Œê³ ë¦¬: {category_name}")
    print(f"ğŸ’Š ì¶”ì²œ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ëª©ë¡ (ìƒìœ„ {top_n}ê°œ):")
    for idx, row in enumerate(top_products.iterrows()):
        row_data = row[1]
        print(f"{idx+1}. {row_data['í’ˆëª©ëª…']} ({row_data['ì£¼ìš” ê¸°ëŠ¥']}) [ìœ ì‚¬ë„: {similarities[top_indices[idx]]:.2f}]")

# ì˜ˆì‹œ ì…ë ¥ í…ŒìŠ¤íŠ¸
user_input = "í—ˆë¦¬ê°€ ì•„íŒŒìš”"
recommend_health_products(user_input, top_n=5)
