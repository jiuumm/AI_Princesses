{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7cd900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Accuracy: 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ê°„ ë° ì†Œí™”       1.00      1.00      1.00        10\n",
      "     ë©´ì—­ ë° ì²´ë ¥       1.00      0.70      0.82        10\n",
      "      ë¼ˆ ë° êµ¬ì¡°       0.83      1.00      0.91        10\n",
      "     ìˆ˜ë©´ ë° ì •ì‹        0.90      0.90      0.90        10\n",
      "    ì‹¬í˜ˆê´€ ë° ëŒ€ì‚¬       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.91      0.90      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "\n",
      "ðŸ§  ì˜ˆì¸¡ëœ ê±´ê°• ì¹´í…Œê³ ë¦¬: ìˆ˜ë©´ ë° ì •ì‹ \n",
      "ðŸ’Š ìµœì¢… ì¶”ì²œ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ (ìƒìœ„ 3ê°œ):\n",
      "1. í™ê²½ì²œ ì¶”ì¶œë¬¼ (ê³ ì‹œí˜• í’ˆëª©)\n",
      "2. ìœ ë‹¨ë°±ê°€ìˆ˜ë¶„í•´ë¬¼ (ê³ ì‹œí˜• í’ˆëª©)\n",
      "3. ëŒì™¸ìžŽì¶”ì¶œë¬¼(ì œ2015-7í˜¸) (ê³ ì‹œí˜• í’ˆëª©)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "individual_data = pd.read_excel('C:\\\\Users\\\\dbwld\\\\OneDrive\\\\ë°”íƒ• í™”ë©´\\\\Project\\\\individual_data.xlsx')\n",
    "nonindividual_data = pd.read_excel('C:\\\\Users\\\\dbwld\\\\OneDrive\\\\ë°”íƒ• í™”ë©´\\\\Project\\\\nonindividual_data.xlsx')\n",
    "symptom_data = pd.read_excel('C:\\\\Users\\\\dbwld\\\\OneDrive\\\\ë°”íƒ• í™”ë©´\\\\Project\\\\symptom_data.xlsx')\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "texts = symptom_data['text']\n",
    "symptom_data['ê±´ê°• ì¹´í…Œê³ ë¦¬'] = symptom_data['ê±´ê°• ì¹´í…Œê³ ë¦¬'].replace('ì •ì‹  ë° ê±´ê°•', 'ìˆ˜ë©´ ë° ì •ì‹ ')\n",
    "labels = symptom_data['ê±´ê°• ì¹´í…Œê³ ë¦¬']\n",
    "\n",
    "# TF-IDF ë²¡í„°í™”\n",
    "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "text_vectors = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# ì˜¤ë²„ìƒ˜í”Œë§ ì ìš© (ë°ì´í„° ë¶ˆê· í˜• í•´ê²°)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(text_vectors, encoded_labels)\n",
    "\n",
    "# ë°ì´í„° ë¶„í•  (Train: 70%, Valid: 15%, Test: 15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled\n",
    ")\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€\n",
    "y_pred = model.predict(X_test)\n",
    "print('ðŸ“ˆ Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# ëª¨ë¸ ë° ë²¡í„° ì €ìž¥\n",
    "joblib.dump(model, 'health_recommendation_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# SBERT ëª¨ë¸ ë¡œë“œ (ì¦ìƒ ìœ ì‚¬ë„ ë¶„ì„ìš© ë° ì„­ì·¨ ì£¼ì˜ì‚¬í•­ ê²€í† ìš© ê°ê° ë‹¤ë¥´ê²Œ ì„¤ì •)\n",
    "symptom_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "warning_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# ê°œì¸í˜• & ë¹„ê°œì¸í˜• ë°ì´í„° ê²°í•©\n",
    "individual_data['í˜•íƒœ'] = 'ê°œë³„ ì¸ì •í˜• í’ˆëª©'\n",
    "nonindividual_data['í˜•íƒœ'] = 'ê³ ì‹œí˜• í’ˆëª©'\n",
    "combined_data = pd.concat([individual_data, nonindividual_data], ignore_index=True)\n",
    "\n",
    "def recommend_health_products(user_input, user_condition, top_n=5):\n",
    "    input_vector = symptom_model.encode(user_input)\n",
    "    symptom_similarities = []\n",
    "    \n",
    "    for idx, row in symptom_data.iterrows():\n",
    "        symptom_embedding = symptom_model.encode(row['text'])\n",
    "        sim = util.cos_sim(np.array([input_vector]), np.array([symptom_embedding]))[0][0].item()\n",
    "        symptom_similarities.append((sim, row['text'], row['ê±´ê°• ì¹´í…Œê³ ë¦¬']))\n",
    "    \n",
    "    top_similar_symptoms = sorted(symptom_similarities, key=lambda x: x[0], reverse=True)[:2]\n",
    "    similar_categories = list(set([item[2] for item in top_similar_symptoms]))\n",
    "    \n",
    "    recommended_products = []\n",
    "    for idx, row in combined_data.iterrows():\n",
    "        if row['ê±´ê°• ì¹´í…Œê³ ë¦¬'] in similar_categories:\n",
    "            product_embedding = symptom_model.encode(row['ì£¼ìš” ê¸°ëŠ¥'])\n",
    "            sim_score = util.cos_sim(input_vector.reshape(1, -1), product_embedding.reshape(1, -1))[0][0].item()\n",
    "            recommended_products.append((row['í’ˆëª©ëª…'], sim_score, row['ì„­ì·¨ ì£¼ì˜ì‚¬í•­'], row['í˜•íƒœ']))\n",
    "    \n",
    "    recommended_products = sorted(recommended_products, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    final_recommendations = []\n",
    "    for prod_name, score, warning, kind in recommended_products:\n",
    "        if is_safe_for_condition(warning, user_condition, threshold=0.45):\n",
    "            final_recommendations.append((prod_name, kind))\n",
    "    \n",
    "    print(f\"\\nðŸ§  ì˜ˆì¸¡ëœ ê±´ê°• ì¹´í…Œê³ ë¦¬: {', '.join(similar_categories)}\")\n",
    "    print(f\"ðŸ’Š ìµœì¢… ì¶”ì²œ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ (ìƒìœ„ {top_n}ê°œ):\")\n",
    "    for idx, (name, kind) in enumerate(final_recommendations):\n",
    "        print(f\"{idx+1}. {name} ({kind})\")\n",
    "\n",
    "def is_safe_for_condition(product_warning, user_condition, threshold=0.45):\n",
    "    if isinstance(product_warning, float) and pd.isna(product_warning):\n",
    "        return True\n",
    "    bullets = product_warning.split('\\n')\n",
    "    for bullet in bullets:\n",
    "        bullet = bullet.strip()\n",
    "        if bullet == \"\":\n",
    "            continue\n",
    "        sim = util.cos_sim(warning_model.encode(bullet).reshape(1, -1), warning_model.encode(user_condition).reshape(1, -1))[0][0].item()\n",
    "        if sim >= threshold:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ì˜ˆì œ ì‹¤í–‰\n",
    "user_input = \"ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§Žì´ ë°›ì•„ìš”\"\n",
    "user_condition = \"ìž„ì‚°ë¶€ì—ìš”\"\n",
    "recommend_health_products(user_input, user_condition, top_n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623ba2b5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numexpr in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (2.8.3)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.10.2-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: bottleneck in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Collecting bottleneck\n",
      "  Downloading Bottleneck-1.4.2-cp39-cp39-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (from numexpr) (1.24.4)\n",
      "Downloading numexpr-2.10.2-cp39-cp39-win_amd64.whl (144 kB)\n",
      "Downloading Bottleneck-1.4.2-cp39-cp39-win_amd64.whl (111 kB)\n",
      "Installing collected packages: numexpr, bottleneck\n",
      "  Attempting uninstall: numexpr\n",
      "    Found existing installation: numexpr 2.8.3\n",
      "    Uninstalling numexpr-2.8.3:\n",
      "      Successfully uninstalled numexpr-2.8.3\n",
      "  Attempting uninstall: bottleneck\n",
      "    Found existing installation: Bottleneck 1.3.5\n",
      "    Uninstalling Bottleneck-1.3.5:\n",
      "      Successfully uninstalled Bottleneck-1.3.5\n",
      "Successfully installed bottleneck-1.4.2 numexpr-2.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numexpr bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf70a8f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dbwld\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1ed83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
